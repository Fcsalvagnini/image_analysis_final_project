epochs: 10
batch_size: 80
path_to_save_model: "../models/"
path_to_save_report: "../report/dataset_v1/"
wandb: True
network: "swin_base_patch4_window7_224"

model:
  SiameseNetworkTimmBackbone:
    network:  swin_base_patch4_window7_224 #"xcit_small_24_p8_224"
    image_size: 200
    nchannels: 3
    transformers: False
  #SimpleConvSiameseNN:
  #  input_size: !!python/tuple [200, 200]


train_dataset:
  BalancedCroppedDataset:
    images_folder: "../data/images_02_cropped_enh_v2/"
    transform: BasicTransformations
    mode: 1 # 0: gray scale | 1: RGB
    subset_images: "../compare_files/train.txt"
    repeat: 4

validation_dataset:
  BalancedCroppedDataset:
    images_folder: "../data/images_02_cropped_enh_v2/"
    transform: BasicTransformations
    mode: 1 # 0: gray scale | 1: RGB
    subset_images: "../compare_files/validation.txt"
    repeat: 4

test_dataset:
  BasicDataset:
    images_folder: "../data/images_02_cropped_enh_v2/"
    compare_file: "../compare_files/compare_splited_v3_test_new.txt"
    transform: BasicTransformations
    mode: 1 # 0: gray scale | 1: RGB

transformation:
  BasicTransformations:
    image_size: !!python/list [200, 200]
    affine_degrees: 5
    affine_translate: !!python/tuple [0.01, 0.02]
    affine_scale: !!python/tuple [0.9, 1.1]
    rotate_degrees: 45

optimizer:
  Adam:
    lr: 0.001
    weight_decay: 0

loss:
  ContrastiveLoss:
    margin: 2.0
    contrastive_threshold: 1.1

test:
  batch_size: 1
