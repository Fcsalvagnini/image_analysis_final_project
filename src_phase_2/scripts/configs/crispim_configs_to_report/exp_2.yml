epochs: 50
batch_size: 32
path_to_save_model: "../models/SimpleConvSiameseNN_dataset_v2/"
path_to_save_report: "../report/SimpleConvSiameseNN_dataset_v2/"
wandb: False
network: SimpleConvSiameseNN_dataset_v2

test:
  batch_size: 1
  verbose: 1

model:
  SimpleConvSiameseNN:
    input_size: !!python/list [140, 140]

train_dataset:
  BalancedCroppedDataset:
    images_folder: "../data/images_02_cropped/"
    transform: BasicTransformations
    mode: 0 # 0: gray scale | 1: RGB
    subset_images: "../compare_files/train.txt"
    repeat: 4
    binarize: True
    invert: True

validation_dataset:
  BalancedCroppedDataset:
    images_folder: "../data/images_02_cropped/"
    transform: BasicTransformations
    mode: 0 # 0: gray scale | 1: RGB
    subset_images: "../compare_files/validation.txt"
    repeat: 1
    binarize: True
    invert: True

test_dataset:
  BalancedCroppedDataset:
    images_folder: "../data/images_02_cropped/"
    transform: BasicTransformations
    mode: 0 # 0: gray scale | 1: RGB
    subset_images: "../compare_files/test.txt"
    repeat: 1
    binarize: True
    invert: True

transformation:
  BasicTransformations:
    image_size: !!python/list [140, 140]
    affine_degrees: 10
    affine_translate: !!python/tuple [0.01, 0.2]
    affine_scale: !!python/tuple [0.8, 1.2]
    rotate_degrees: 45
    gaussian_blur_kernel: !!python/tuple [3, 3]
    random_erasing_p: 0.5
    random_erasing_scale: !!python/tuple [0.02, 0.3]


optimizer:
  Adam:
    lr: 0.001
    weight_decay: 0

loss:
  ContrastiveLoss:
    margin: 2.0
    contrastive_threshold: 1.1